{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Todays exercise - the maximum number of points you can acheive is 100. The points are dispersed throughout the exercises : \n",
    "Based on the content of the lecture today you should be able to solve the following notebook and answer the questions. When you are asked to explain somethin please **do not** copy/paste but always use your own words (you will not be given points for copy/paste answers!)\n",
    "\n",
    "You can write with questions at any time, however, help will mainly be available in the hours allocated after lecture, BUT:\n",
    "\n",
    "If you are not able to immediately answer something please look in the relevant links to the sickit-learn documentation that are provided throughout the notebook. \n",
    "\n",
    "If there is not a relevant link for the question, PLEASE try to google before asking. You will learn more and work faster if you try to search out information for yourself. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Random Forest exercise\n",
    "\n",
    "Random Forest on the N-terminus of proteins. The dataset cosists of two classes of proteins: Secretory and Non-secretory. The input consists of 20 features, which corresponds to the amino acid frequencies of the first 30 amino acids of a protein (N-terminal part). \n",
    "Here we are going to use Random forest to classify the proteins based on the amino acid frequencies of the first 30 residues.\n",
    "\n",
    "### Import all the packages that we are going to need\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q1 (2 points): First we need to load some data. We load in a test data set and a training data set. The test data set will not be used for training the random forest. Both data sets contain measured frequency data values and the belonging labels, that is whether Sectretory or Non-Secretory. \n",
    "\n",
    "The data we will be using here is the data we generated and clustered the other day with CD-hit!  \n",
    "\n",
    "**You will be figuring out yourself how to load the data.**  \n",
    "\n",
    "**Hints:** 1) you have to think about what kind of file you are dealing with, 2) one of the libraries loaded into your environment might have a useful loading package (or check out numpy loading packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-freddie2\n",
      "/home/jupyter-freddie2/ml_data\n",
      "ln: failed to create symbolic link './freq_train.txt': File exists\n",
      "ln: failed to create symbolic link './freq_val.txt': File exists\n",
      "ln: failed to create symbolic link './label_train.txt': File exists\n",
      "ln: failed to create symbolic link './label_val.txt': File exists\n",
      "/home/jupyter-freddie2/ml_data\n",
      "freq_train.txt\tfreq_val.txt  label_train.txt  label_val.txt\n"
     ]
    }
   ],
   "source": [
    "# command to make symbolic link\n",
    "%cd\n",
    "%cd ml_data\n",
    "!ln -s /exercises/ml_intro/ml_data/freq_train.txt ./freq_train.txt\n",
    "!ln -s /exercises/ml_intro/ml_data/freq_val.txt ./freq_val.txt \n",
    "!ln -s /exercises/ml_intro/ml_data/label_train.txt ./label_train.txt\n",
    "!ln -s /exercises/ml_intro/ml_data/label_val.txt ./label_val.txt \n",
    "!pwd\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Below are the names of the files use these strings to load the data (you have loaded such files before with numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "`'freq_train.txt'`\n",
    "\n",
    "`'freq_val.txt'`\n",
    "\n",
    "`'label_train.txt'`\n",
    "\n",
    "`'label_val.txt'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-54c11c4e324b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-54c11c4e324b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    X_train = ?\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X_train = ?\n",
    "y_train = ?\n",
    "X_test = ?\n",
    "y_test = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Now we can define the random forest model. \n",
    "##### Go to the sklearn random forest (http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) website and find out how to set up and train a random forest!\n",
    "##### Pay attention to the tunable parameters in the model and note them down? Which do you think are most important\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q2 (6 points): Set up the random forest model and fit it to the training data. Explain the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-281569a488f0>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-281569a488f0>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    rf_model = ??\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# set up the model:\n",
    "rf_model = ??\n",
    "# train the model:\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Next we will use the trained model to make predictions! \n",
    "**It is important to have a metric to evaluate the performance of the model. In this case we will calculate the accuracy and show the confusion matrix.**\n",
    "### Q3 (6 points): Explain what accuracy (ACC) and confusion matrix represents. How would these look for a random model and a perfect model?\n",
    "**Hint:** How are the True positive & true negative related to accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q4 (5 points): Report ACC and confusion matrix values!\n",
    "##### Link for confusion matrix visualization (https://tatwan.github.io/How-To-Plot-A-Confusion-Matrix-In-Python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-039efc104adb>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-039efc104adb>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    y_test_pred = ??\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# use the model to make predictions: \n",
    "y_test_pred = ??\n",
    "# accuracy:\n",
    "acc = ??\n",
    "print(\"Accuracy: \" + str(round(acc,3)))\n",
    "# calculate confusion matrix:\n",
    "cm = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Let's visualize the confusion matrix for better understanding\n",
    "### Q5 (2 point): **Most of the code is already written BUT you need to add the correct labels to the x and y axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix:\n",
    "plt.clf()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia) \n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Confusion Matrix')\n",
    "tick_marks = np.arange(len(classNames)) \n",
    "plt.xticks(tick_marks, classNames, rotation=45) \n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "# PLEASE ADD THE X AND Y AXIS LABELS BELOW:\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q6 (2 points): Describe what you see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now we will investigate how the number of trees influences the random forest accuracy! \n",
    "### Q7 (2 points): finish the code below. Is the number of trees a hyperparameter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-c3ff426c6329>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-c3ff426c6329>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    rf_model = ??\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# test different number of trees: \n",
    "number_trees=[1,5,10,50,100,150,200]\n",
    "perf=[]\n",
    "for n in number_trees: # set up the model: \n",
    "    rf_model = ??\n",
    "    # train the model:\n",
    "    ??\n",
    "    # predict:\n",
    "    y_test_pred = ??\n",
    "    # calculate ACC:\n",
    "    perf.append(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# visualize result:\n",
    "plt.plot(number_trees,perf)\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('performance in AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q8 (1 point): How many trees do you need to achieve satisfactory performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q9 (7 points): Explain for what reason having multiple decision trees (i.e. Random Forest) is better than having just one and how is the \"randomness\" in the random forest acheived? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### We can see that the number of trees in  the forest have an impact on performance. But there are other parameters we can tune as well!\n",
    "#### Let's try to search for the optimal combination of values for a couple of parameters: number of trees, max depth of trees, max features. \n",
    "##### In this case we only test a few hyperparameters but keep in mind that there are more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q10 (7 points): First explain briefly in your OWN words what the hyperparameters control? (since you have already explained the number of trees now explain: max depth of trees, max features). Is there one or more other hyperparameters that we can tune to try to reduce overfitting?\n",
    "**Hint:** Think about what you learned in the lecture today and look in the documentation http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### To search for the optimal number of parameters we will do a grid search (i.e. we search a grid containing the possible combinations of hyperparameter values). This can be done manually but sklearn can also help with this .   \n",
    "**You will need to code most of the hyperparameter tuning yourself but we will take it step by step** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### First we need to make a grid containing all the possible combinations of values for the hyperparameters we want to use\n",
    "**Go to https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html**\n",
    "\n",
    "\n",
    "**Hint:** To generate an array for `n_trees` and `max_depth` we are using `np.arange()` you can read about `np.arange` here: https://numpy.org/doc/stable/reference/generated/numpy.arange.html\n",
    "\n",
    "### Q11 (5 points): make a parameter grid using the sklearn function `ParameterGrid`. How many different combinations are we searching?\n",
    "**Hint**: to get the number of parameters think about how you get the length of a list or array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-242-7090b2e2befa>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-242-7090b2e2befa>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    params = ? # here you need to go to https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html and read hot to do it\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "max_depth = list(np.arange(1, 101, 10))\n",
    "max_depth.append(None)\n",
    "n_trees = list(np.arange(1, 1001, 50))\n",
    "max_features = ['auto', 'log2']\n",
    "\n",
    "params = ? # here you need to go to https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html and read hot to do it \n",
    "param_grid = ParameterGrid(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q12 (3 points): why are we only testing 2 options for `max_features` when there are three: 'auto', 'sqrt', 'log2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Because auto and sqrt are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Usuallly we would have to test more than 3 hyperparameters which would result in a huge number of combinations. Then it will take way to long to search all the combinations to test. We can narrow in out search in 2 ways:\n",
    "- do a rough search with bigger steps. Then search more thoroughly around the best performing combination.\n",
    "- pick a number of random combinations to test. Then search more thoroughly around the best performing combination.\n",
    "\n",
    "### Here we will do the latter. We will pick out 100 random combinations and search those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "random_params = random.sample(param_grid, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now we will find the optimal combination of hyperparameters in the random set.   \n",
    "**Usually for this proccess we would use k-fold cross validation, but today we are simply using the train and validation set** \n",
    "### Q13 (5 points): For what purpose were we making sure that the sequences in the training and validation datasets are not too similar? \n",
    "**In cross validation we would also make sure that the partitions are not too similar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q14 (4 points): What are some reason/advantages for usually using cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q15 (8 points): Inspired by the code used to search for the optimal number of trees train and predict using each of the combinations in the `random_params`\n",
    "\n",
    "\n",
    "**Hint:** You can loop through the `random_params` and get the value of e.g. n_trees in that combination of hyperparameters by:  \n",
    "\n",
    "` for p in random_params:   \n",
    "     n_trees = p['n_trees']`\n",
    "\n",
    "**Hint:** Save the accuracy on the validation set of the model for each combination of the hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-28-23fdd87d7185>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-23fdd87d7185>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    # write the rest of the loop yourself.\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "performance = []\n",
    "\n",
    "for params in random_params:\n",
    "    # write the rest of the loop yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q16 (4 points): What combination of hyperparameters give the highest accuracy? Do you think this accuracy significantly better than the one for the default model (the first you trained). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-30-132b3eec3318>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-132b3eec3318>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    original_acc = ? # put the accuracy of your original model here\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "max_acc = max(performance)\n",
    "i = performance.index(max(performance))\n",
    "original_acc = ? # put the accuracy of your original model here\n",
    "print('origninal accuracy:' ,original_acc, 'new max accuracy:', np.round(max_acc, 3), ', Parameter values:' , param_grid[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "No it is 1% higher only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Let us take a look at the top 10 settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "highest_perf = sorted(range(len(performance)), key = lambda sub: performance[sub], reverse=True)[:10] \n",
    "\n",
    "for i in highest_perf:\n",
    "    print('accuracy:', performance[i], random_params[i] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Repeat the exercise narrowing in on the best parameter settings: \n",
    "We can see that there is actually quite a bit of variation in the best performing parameters. Let us narrow in the search according to the best performing hyperparameters (Be aware that your results may be slightly different, but still use the narrowed down search as below)\n",
    "- n_trees from 150-250 (stepsize 10)\n",
    "- max depth from 20-50 + None (stepsize 5)\n",
    "### Q17 (9 points) : Finish the code below and report the best accuracy and the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-250-fbd697ddb43a>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-250-fbd697ddb43a>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    params = ?\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "max_depth = list(np.arange(15, 70, 5))\n",
    "max_depth.append(None)\n",
    "n_trees = np.arange(150, 250, 10)\n",
    "params = ? \n",
    "param_grid = ?\n",
    "\n",
    "performance = []\n",
    "for params in param_grid:\n",
    "\n",
    "    # code the rest yourself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q18 (4 points): Now let's have a look at the feature importance reported by the random forest. Begin by training a random forest with the optimal hyperparameters. Next, extract the feature importance and visualize which genes are important for determining whether Sectretory or Non-sectretory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-3bea352049d4>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-3bea352049d4>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    n_trees = ?\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "aa_labels = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "\n",
    "#setupandfitthemodel: \n",
    "n_trees = ?\n",
    "max_features = ?\n",
    "max_depth = ?\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=n_trees, max_features=max_features, max_depth =max_depth)\n",
    "rf_model.fit(X_train, y_train)\n",
    "# visualize importance per position:\n",
    "feature_imp = rf_model.feature_importances_\n",
    "feature_imp = np.reshape(feature_imp, [-1,1])\n",
    "# show feature importance per amino acid as boxplot:\n",
    "plt.bar(np.arange(len(aa_labels)),feature_imp[:,0])\n",
    "plt.xlabel('amino acid')\n",
    "plt.ylabel('importance')\n",
    "tick_marks = np.arange(len(aa_labels))\n",
    "plt.xticks(tick_marks, aa_labels) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q19 (2 points): Which features are more important than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q20 (3 points): What is the biological interpretation of the barplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q21 (5 points): look in day 2 exercises - we did a boxplot for the amino acid frequencies for secretory vs non-secretory. Make this boxplot again.\n",
    "### Does the random forest feature importance validate that plot? What do the labels `0` and `1` signify biologically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-a28dc24f3f59>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a28dc24f3f59>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    df = ?\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# make a dataframe\n",
    "df = ? \n",
    "df['label'] = y_train\n",
    "# use pd.melt to change the shape of the dataframe \n",
    "melted_data = pd.melt(df, id_vars='label')\n",
    "# use sns.boxplot to plot https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "# plot the melted_data\n",
    "sns.boxplot(data = ?, x = ?, y=?, hue='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Q23 (2 points): what is the Out-of-bag error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
